{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG1_zZBjNuM1"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece] python-docx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast, BertForTokenClassification, BertForSequenceClassification, BertModel\n",
        "from transformers import BertConfig\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import TextDataset"
      ],
      "metadata": {
        "id": "uKo0d9ltN6aM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Read the JSON file\n",
        "path = \"/content/drive/MyDrive/model/B_data.json\"\n",
        "with open(path, 'r') as f:\n",
        "    dataset = json.load(f)"
      ],
      "metadata": {
        "id": "NmR5din-N8Zq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/model/training_set.json\"\n",
        "with open(path, 'r') as f:\n",
        "    test_dataset = json.load(f)"
      ],
      "metadata": {
        "id": "ChyWzbcAOCAC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text, intent, ner = [], [], []\n",
        "for i in dataset:\n",
        "    text.append(i['text'])\n",
        "    intent.append(i['intent'])\n",
        "    ner.append(i['entities'].split())"
      ],
      "metadata": {
        "id": "nRzWOIZ7OCpa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text, test_intent, test_ner = [], [], []\n",
        "for i in test_dataset:\n",
        "    test_text.append(i['text'])\n",
        "    test_intent.append(i['intent'])\n",
        "    test_ner.append(i['entities'].split())"
      ],
      "metadata": {
        "id": "b-NXvXb9OELC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_intents = set(intent)\n",
        "num_intent_labels = len(unique_intents)\n",
        "\n",
        "unique_intents, num_intent_labels"
      ],
      "metadata": {
        "id": "TSqnFLXSOFpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca36a587-bfe9-4f76-af50-d75805aed969"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({\"'Schedule Appointment'\",\n",
              "  \"'Schedule Meeting'\",\n",
              "  \"'Set Alarm'\",\n",
              "  \"'Set Reminder'\",\n",
              "  \"'Set Timer'\"},\n",
              " 5)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_dimensional_ner = [tag for subset in ner for tag in subset ]\n",
        "unique_ner = set(one_dimensional_ner)\n",
        "num_ner_labels = len(unique_ner)\n",
        "unique_ner, num_ner_labels"
      ],
      "metadata": {
        "id": "Yq7QUTyAOHQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab03388-4225-46a7-a183-f7890ebe7f4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'B-DATE',\n",
              "  'B-DUR',\n",
              "  'B-TASK',\n",
              "  'B-TIME',\n",
              "  'I-DATE',\n",
              "  'I-DUR',\n",
              "  'I-TASK',\n",
              "  'I-TIME',\n",
              "  'O'},\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "ner_model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=num_ner_labels)\n",
        "intent_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_intent_labels)\n",
        "bert_backbone = BertModel.from_pretrained('bert-base-uncased')\n",
        "config = BertConfig.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "XawZZRogOI_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2eb1ed9-fc54-4203-c30d-bd123c547eb1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_to_ids_ner = {\n",
        "    'O': 0,\n",
        "    'B-DATE': 1,\n",
        "    'I-DATE': 2,\n",
        "    'B-TIME': 3,\n",
        "    'I-TIME': 4,\n",
        "    'B-TASK': 5,\n",
        "    'I-TASK': 6,\n",
        "    'B-DUR': 7,\n",
        "    'I-DUR': 8\n",
        "    }\n",
        "\n",
        "ids_to_labels_ner = {v: k for k, v in labels_to_ids_ner.items()}\n",
        "ids_to_labels_ner"
      ],
      "metadata": {
        "id": "oIOr8LgdOMFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6268ed68-17eb-4c3b-b92d-914ca0a95a9d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'O',\n",
              " 1: 'B-DATE',\n",
              " 2: 'I-DATE',\n",
              " 3: 'B-TIME',\n",
              " 4: 'I-TIME',\n",
              " 5: 'B-TASK',\n",
              " 6: 'I-TASK',\n",
              " 7: 'B-DUR',\n",
              " 8: 'I-DUR'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_to_ids_intent = {\n",
        "    \"'Schedule Appointment'\": 0,\n",
        "    \"'Schedule Meeting'\": 1,\n",
        "    \"'Set Alarm'\": 2,\n",
        "    \"'Set Reminder'\": 3,\n",
        "    \"'Set Timer'\": 4\n",
        "}\n",
        "\n",
        "ids_to_labels_intent = {v: k for k, v in labels_to_ids_intent.items()}\n",
        "ids_to_labels_intent"
      ],
      "metadata": {
        "id": "WP5okVE_OOwC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e3d347-31c8-4417-c69a-5b08f969d017"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: \"'Schedule Appointment'\",\n",
              " 1: \"'Schedule Meeting'\",\n",
              " 2: \"'Set Alarm'\",\n",
              " 3: \"'Set Reminder'\",\n",
              " 4: \"'Set Timer'\"}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset):\n",
        "    def __init__(self, text, intent, ner, tokenizer, max_len=128):\n",
        "        self.len = len(text)\n",
        "        self.text = text\n",
        "        self.intent = intent\n",
        "        self.ner = ner\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: get the sentence, ner label, and intent_label\n",
        "        sentence = self.text[index].strip()\n",
        "        intent_label = self.intent[index].strip()\n",
        "        ner_labels = self.ner[index]\n",
        "\n",
        "        # step 2: use tokenizer to encode a sentence (includes padding/truncation up to max length)\n",
        "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" which highlights where each token starts and ends\n",
        "        encoding = self.tokenizer(\n",
        "            sentence,\n",
        "            return_offsets_mapping=True,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_len\n",
        "        )\n",
        "\n",
        "        # step 3: create ner token labels only for first word pieces of each tokenized word\n",
        "        tokenized_ner_labels = [labels_to_ids_ner[label] for label in ner_labels]\n",
        "        # create an empty array of -100 of length max_length\n",
        "        encoded_ner_labels = np.ones(len(encoding['offset_mapping']), dtype=int) * -100\n",
        "\n",
        "        # set only labels whose first offset position is 0 and the second is not 0\n",
        "        i = 0\n",
        "        prev = -1\n",
        "        for idx, mapping in enumerate(encoding['offset_mapping']):\n",
        "            if mapping[0] == mapping[1] == 0:\n",
        "                continue\n",
        "            if mapping[0] != prev:\n",
        "                # overwrite label\n",
        "                encoded_ner_labels[idx] = tokenized_ner_labels[i]\n",
        "                prev = mapping[1]\n",
        "                i += 1\n",
        "            else:\n",
        "                prev = mapping[1]\n",
        "\n",
        "        # create intent token labels\n",
        "        tokenized_intent_label = labels_to_ids_intent[intent_label]\n",
        "\n",
        "        # step 4: turn everything into Pytorch tensors\n",
        "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
        "        item['ner_labels'] = torch.as_tensor(encoded_ner_labels)\n",
        "        item['intent_labels'] = torch.as_tensor(tokenized_intent_label)\n",
        "\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "GD2hhkYWOQiy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = dataset(text, intent, ner, tokenizer)\n",
        "test_set = dataset(test_text, test_intent, test_ner, tokenizer)"
      ],
      "metadata": {
        "id": "QzZaSdx0OT38"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[20]['input_ids']), training_set[20]['ner_labels']):\n",
        "    print(f\"{token} -- {label}\")"
      ],
      "metadata": {
        "id": "qlHH71-3OWd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98489233-671b-45b8-ba0d-d250756d8893"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] -- -100\n",
            "schedule -- 0\n",
            "a -- 0\n",
            "dentist -- 5\n",
            "appointment -- 6\n",
            "for -- 0\n",
            "april -- 1\n",
            "5th -- 2\n",
            "at -- 0\n",
            "11 -- 3\n",
            ": -- -100\n",
            "00 -- -100\n",
            "in -- 4\n",
            "the -- 4\n",
            "morning -- 4\n",
            ". -- -100\n",
            "[SEP] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n",
            "[PAD] -- -100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The dataset is small, batch_size of 1 would not impact the training time significantly\n",
        "training_loader = DataLoader(training_set, batch_size=1)\n",
        "test_loader = DataLoader(test_set, batch_size=1)"
      ],
      "metadata": {
        "id": "O7CtBSAROZla"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "UhinzuBnOcKr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "qRtTRygxOdpd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9d0b3016-0312-4741-f82f-efbc6ecf0ed6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_model.to(device)\n",
        "intent_model.to(device)"
      ],
      "metadata": {
        "id": "D80nUJfwOesz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33141fb2-cdf5-447f-b573-2ad921f5c575"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intent_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxg924LJTy5h",
        "outputId": "a49650d7-5529-474c-c41d-4f22ce637b29"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsZV41f7Si_o",
        "outputId": "c1363ccc-a7b2-4571-eff7-586687d264d8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_backbone"
      ],
      "metadata": {
        "id": "h6DomtlwIssm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0264c311-60ba-435a-deb6-c9b738f31a0d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTq1Iwe_iIE8",
        "outputId": "671b3642-166a-450e-8558-a767765898db"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.35.2\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30522\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam([\n",
        "    {'params': ner_model.parameters()},\n",
        "    {'params': intent_model.parameters()}\n",
        "], lr=1e-5)"
      ],
      "metadata": {
        "id": "-kVD2zy8OoOD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Task Learning Arcitecture"
      ],
      "metadata": {
        "id": "ESSOrSEdOr_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskBertModel(BertModel):\n",
        "    def __init__(self, config, input_ids, attention_mask, token_type_ids, num_ner_labels, num_intent_labels):\n",
        "        super().__init__(config)\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.num_ner_labels = num_ner_labels\n",
        "        self.num_intent_labels = num_intent_labels\n",
        "        self.ner_classifier = torch.nn.Linear(config.hidden_size, self.num_ner_labels)\n",
        "        self.intent_classifier = torch.nn.Linear(config.hidden_size, self.num_intent_labels)\n",
        "\n",
        "    def forward(self):\n",
        "        outputs = super().forward(self.input_ids, self.attention_mask, self.token_type_ids)\n",
        "        sequence_output = outputs[0]\n",
        "        ner_logits = self.ner_classifier(sequence_output)\n",
        "        intent_logits = self.intent_classifier(sequence_output)\n",
        "        return ner_logits, intent_logits\n"
      ],
      "metadata": {
        "id": "LfEsaNqpOuwO"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}